{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq8/349zIDzxVegqB9oXd0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EvansAmarh/Scratch/blob/main/Scratch0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U5psjPeHV-u",
        "outputId": "be0bd102-736a-4658-973e-fe53f1d52476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14.280000000000001, 12.299999999999999, 14.899999999999999]\n"
          ]
        }
      ],
      "source": [
        "inputs = [1.2, 5.1, 2.1]\n",
        "\n",
        "weights1 = [3.1, -2.1, 8.7, 1.0]\n",
        "weights2 = [1.1, 2.1, -1.3, 3.0]\n",
        "weights3 = [0.1, 2.1, 1.7, -1.0]\n",
        "\n",
        "bias1 = 3\n",
        "bias2 = 3\n",
        "bias3 = 0.5\n",
        "\n",
        "output = [inputs[0]*weights1[0] + inputs[1]*weights1[1] + inputs[2]*weights1[2] + bias1,\n",
        "inputs[0]*weights2[0] + inputs[1]*weights2[1] + inputs[2]*weights2[2] + bias2,\n",
        "inputs[0]*weights3[0] + inputs[1]*weights3[1] + inputs[2]*weights3[2] + bias3]\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1.2, 5.1, 2.1]\n",
        "\n",
        "weights = [[3.1, -2.1, 8.7, 1.0], [1.1, 2.1, -1.3, 3.0], [0.1, 2.1, 1.7, -1.0]]\n",
        "\n",
        "biases = [2, 3, 0.5]\n",
        "\n",
        "some_value = -0.5\n",
        "weight = 0.7\n",
        "bias = 0.7\n",
        "\n",
        "print(some_value*weight)\n",
        "print(some_value+bias)\n",
        "\n",
        "'''layer_outputs = [] # Output of current layer\n",
        "for neuron_weights, neuron_bias in zip(weights, biases):\n",
        "  neuron_output = 0 # Output of given neuron\n",
        "  for n_input, weight in zip(inputs, neuron_weights):\n",
        "    neuron_output += n_input*weight\n",
        "  neuron_output += neuron_bias\n",
        "  layer_outputs.append(neuron_output)\n",
        "\n",
        "print(layer_outputs)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "RtRcWK4THwWf",
        "outputId": "d7862cb0-1a97-4bea-c187-76c8e651428d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.35\n",
            "0.19999999999999996\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'layer_outputs = [] # Output of current layer\\nfor neuron_weights, neuron_bias in zip(weights, biases):\\n  neuron_output = 0 # Output of given neuron\\n  for n_input, weight in zip(inputs, neuron_weights):\\n    neuron_output += n_input*weight\\n  neuron_output += neuron_bias\\n  layer_outputs.append(neuron_output)\\n\\nprint(layer_outputs)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "inputs = [1.2, 5.1, 2.1]\n",
        "weights = [[3.1, -2.1, 8.7], [1.1, 2.1, -1.3], [0.1, 2.1, 1.7]] # Updated weights to match input shape\n",
        "biases = [2, 3, 0.5] # Using biases from previous cell\n",
        "\n",
        "output = np.dot(inputs, np.array(weights).T) + biases # Transpose weights to align shapes\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63Mh9DTxQRHn",
        "outputId": "74b13319-3862-47f4-f594-44c1ed6dce09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13.28 12.3  14.9 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "inputs = [[1.2, 5.1, 2.1], [0.2, 2.1, 2.2,], [-1.5, 5.1, -2.3]]\n",
        "weights = [[3.1, -2.1, 8.7], [1.1, 2.1, -1.3], [0.1, 2.1, 1.7]] # Updated weights to match input shape\n",
        "biases = [2, 3, 0.5] # Using biases from previous cell\n",
        "\n",
        "output = np.dot(weights, inputs) + biases # Transpose weights to align shapes\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8uC_75AQ_o7",
        "outputId": "5d5dcfbc-8788-4875-fd8a-39d89d7b3989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-7.750e+00  5.877e+01 -1.762e+01]\n",
            " [ 5.690e+00  6.390e+00  1.042e+01]\n",
            " [-1.000e-02  1.659e+01  1.420e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "X = [[1, 2, 3, 2.5], [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "X, y = spiral_data(100, 3)\n",
        "\n",
        "class Layer_Dense:\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
        "    self.biases = np.zeros((1, n_neurons))\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "class Activation_Relu:\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.maximum(0, inputs)\n",
        "\n",
        "layer1 = Layer_Dense(2, 4)\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "layer1.forward(X)\n",
        "# print(layer1.output)\n",
        "activation1.forward(layer1.output)\n",
        "print(activation1.output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi0kaBt4aUig",
        "outputId": "968e6544-8972-4431-cb27-4ecbc8928a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.70921061 -0.00184155  0.44207036  0.71351851]\n",
            " [ 0.14468757 -0.1981251   0.12173849  0.07621588]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "layer_outputs = [4.8, 1.21, 2.385]\n",
        "E = math.e\n",
        "\n",
        "exp_values = []\n",
        "\n",
        "for output in layer_outputs:\n",
        "  exp_values.append(E**output)\n",
        "\n",
        "print(exp_values)\n",
        "\n",
        "norm_base = sum(exp_values)\n",
        "norm_values = []\n",
        "\n",
        "for value in exp_values:\n",
        "  norm_values.append(value / norm_base)\n",
        "\n",
        "print(norm_values)\n",
        "print(sum(norm_values))"
      ],
      "metadata": {
        "id": "iJTXskyYrjHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "\n",
        "layer_outputs = [[4.8, 1.21, 2.385], [8.9, -1.81, 0.2], [1.41, 1.051, 0.026]]\n",
        "\n",
        "exp_values = np.exp(layer_outputs)\n",
        "\n",
        "norm_values = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "print(norm_values)\n",
        "\n"
      ],
      "metadata": {
        "id": "O9FSG4rOLRJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "\n",
        "\n",
        "X, y = spiral_data(100, 3)\n",
        "\n",
        "class Layer_Dense:\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
        "    self.biases = np.zeros((1, n_neurons))\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "class Activation_Relu:\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.maximum(0, inputs)\n",
        "\n",
        "class Activation_Softmax:\n",
        "  def forward(self, inputs):\n",
        "    exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
        "    probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "    self.output = probabilities\n",
        "\n",
        "class Loss:\n",
        "  def calculate(self, output, y):\n",
        "    sample_losses = self.forward(output, y)\n",
        "    data_loss = np.mean(sample_losses)\n",
        "    return data_loss\n",
        "\n",
        "class Loss_CategorivalCrossEntropy(Loss):\n",
        "  def forward(self, y_pred, y_true):\n",
        "    samples = len(y_pred)\n",
        "    y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7)\n",
        "\n",
        "    if len(y_true.shape) == 1:\n",
        "      correct_confidences = y_pred_clipped[range(samples), y_true]\n",
        "    elif len(y_true.shape) == 2:\n",
        "      correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
        "\n",
        "    negative_log_likelihoods = -np.log(correct_confidences)\n",
        "    return negative_log_likelihoods\n",
        "\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "dense1 = Layer_Dense(2,3)\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "dense1 = Layer_Dense(3,3)\n",
        "activation2 = Activation_Softmax()\n",
        "\n",
        "dense1.forward(X)\n",
        "activation1.forward(dense1.output)\n",
        "\n",
        "dense2.forward(activation1.output)\n",
        "activation2.forward(dense2.output)\n",
        "\n",
        "print(activation2.output[:5])\n",
        "\n",
        "loss_function = Loss_CategoricalCrossEntropy()\n",
        "loss = loss_function.calculate(activation2.output, y)\n",
        "\n",
        "print(\"Loss:\", loss)\n"
      ],
      "metadata": {
        "id": "G-O4WKYyOdTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "softmax_output = [0.7, 0.1, 0.2]\n",
        "target_output = [1, 0, 0]\n",
        "\n",
        "loss = -(math.log(softmax_output[0])*target_output[0] +\n",
        "         math.log(softmax_output[1])*target_output[1] +\n",
        "         math.log(softmax_output[2])*target_output[2])\n",
        "print(loss)\n",
        "\n",
        "loss = -math.log(softmax_output[0])\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "DWHrcwwHWLot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "softmax_outputs = np.array([[0.7, 0.1, 0.2],\n",
        "                            [0.1, 0.5, 0.4],\n",
        "                            [0.02, 0.9, 0.08]])\n",
        "class_targets = [0, 1, 1]\n",
        "\n",
        "print(-np.log(softmax_outputs[[0, 1, 2], class_targets]))"
      ],
      "metadata": {
        "id": "joIubLG1hrNB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}